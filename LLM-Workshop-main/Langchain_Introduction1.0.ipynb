{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f24931-b6a7-4255-97eb-2425f30ba8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv ,find_dotenv\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8d8576-3b18-4981-bcf5-caad1730717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517da050-c000-4005-b2ae-5400f0bfe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4f020d-a105-4ebf-8cd9-85ac0fa15e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(),override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005cece-1c8b-456f-ac05-151ff12ca9e3",
   "metadata": {},
   "source": [
    "## LLM WRAPPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3332b7ab-de55-4b4a-b5fd-0bf2865d5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dbe4555-5ce5-4572-bdeb-2a73b012053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verma\\anaconda3\\envs\\llm_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184a3472-e98f-4999-8a76-420df8b33d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(chat_model.get_num_tokens('explain india in one senetence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affaaead-5282-4086-a204-9c35e1a2691f",
   "metadata": {},
   "source": [
    "## simple prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cdb12af-7f47-4085-9d38-92e6f6aa544d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of my last update, the Prime Minister of India is Narendra Modi.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"who is prime minister of india\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230a85b-3915-4f2b-83f4-395733ac241d",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532d72f2-ea1b-4912-bb81-9f980514ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "934277a9-63ba-4388-85d0-09e3e58628f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template='''you are experienced healthcare assistant having knowledge of medicine and its side effects .\n",
    "            Suggest few side effects and Prevention  about the following {medicine}  in {language}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2227f986-cc4c-4bd4-afb6-5eb1b035099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(input_variables=['medicine','language'],template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11b06811-9c92-453b-996a-4767994cb153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language', 'medicine'], template='you are experienced healthcare assistant having knowledge of medicine and its side effects .\\n            Suggest few side effects and Prevention  about the following {medicine}  in {language}')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef568a7d-755d-4464-a096-c894cbdbd16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§Ø‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§¶‡§µ‡§æ ‡§Æ‡§æ‡§®‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§á‡§∏‡§ï‡•á ‡§ï‡•Å‡§õ ‡§∏‡§æ‡§á‡§° ‡§á‡§´‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§≠‡•Ä ‡§π‡•ã ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
      "\n",
      "‡§∏‡§æ‡§á‡§° ‡§á‡§´‡•á‡§ï‡•ç‡§ü‡•ç‡§∏:\n",
      "\n",
      "1. ‡§™‡•á‡§ü ‡§¶‡§∞‡•ç‡§¶: ‡§Ø‡§π ‡§¶‡§µ‡§æ ‡§™‡•á‡§ü ‡§Æ‡•á‡§Ç ‡§¶‡§∞‡•ç‡§¶ ‡§Ø‡§æ ‡§Ö‡§∏‡§π‡§ú‡§§‡§æ ‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§¨‡§® ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§\n",
      "\n",
      "2. ‡§§‡•ç‡§µ‡§ö‡§æ ‡§™‡§∞ ‡§≤‡§æ‡§≤ ‡§ö‡§ï‡§§‡•ç‡§§‡•á ‡§Ø‡§æ ‡§ñ‡•Å‡§ú‡§≤‡•Ä: ‡§á‡§∏‡•á ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ï‡•Å‡§õ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ç‡§µ‡§ö‡§æ ‡§™‡§∞ ‡§≤‡§æ‡§≤ ‡§ö‡§ï‡§§‡•ç‡§§‡•á ‡§Ø‡§æ ‡§ñ‡•Å‡§ú‡§≤‡•Ä ‡§π‡•ã ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§\n",
      "\n",
      "3. ‡§®‡•å‡§∏‡§ø‡§Ø‡§æ ‡§Ø‡§æ ‡§â‡§≤‡•ç‡§ü‡•Ä: ‡§Ø‡§π ‡§¶‡§µ‡§æ ‡§®‡•å‡§∏‡§ø‡§Ø‡§æ ‡§Ø‡§æ ‡§â‡§≤‡•ç‡§ü‡•Ä ‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§¨‡§® ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§\n",
      "\n",
      "4. ‡§ö‡§ï‡•ç‡§ï‡§∞ ‡§Ü‡§®‡§æ: ‡§ï‡•Å‡§õ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§á‡§∏‡•á ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ö‡§ï‡•ç‡§ï‡§∞ ‡§Ü ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
      "\n",
      "‡§™‡•ç‡§∞‡•Ä‡§µ‡•á‡§Ç‡§∂‡§®:\n",
      "\n",
      "1. ‡§Ö‡§ó‡§∞ ‡§Ü‡§™‡§ï‡•ã ‡§™‡•á‡§ü ‡§¶‡§∞‡•ç‡§¶ ‡§π‡•ã, ‡§§‡•ã ‡§á‡§∏‡•á ‡§≠‡•ã‡§ú‡§® ‡§ï‡•á ‡§∏‡§æ‡§• ‡§≤‡•á‡§Ç‡•§\n",
      "\n",
      "2. ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§§‡•ç‡§µ‡§ö‡§æ ‡§™‡§∞ ‡§≤‡§æ‡§≤ ‡§ö‡§ï‡§§‡•ç‡§§‡•á ‡§Ø‡§æ ‡§ñ‡•Å‡§ú‡§≤‡•Ä ‡§π‡•ã, ‡§§‡•ã ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§\n",
      "\n",
      "3. ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§®‡•å‡§∏‡§ø‡§Ø‡§æ ‡§Ø‡§æ ‡§â‡§≤‡•ç‡§ü‡•Ä ‡§π‡•ã, ‡§§‡•ã ‡§á‡§∏‡•á ‡§≠‡•ã‡§ú‡§® ‡§ï‡•á ‡§∏‡§æ‡§• ‡§≤‡•á‡§Ç‡•§\n",
      "\n",
      "4. ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ö‡§ï‡•ç‡§ï‡§∞ ‡§Ü ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§Ü‡§™‡§ï‡•ã ‡§ß‡•Ä‡§Æ‡•Ä ‡§ó‡§§‡§ø ‡§∏‡•á ‡§â‡§†‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è ‡§î‡§∞ ‡§ú‡§¨ ‡§§‡§ï ‡§Ü‡§™ ‡§†‡•Ä‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§ú‡§æ‡§§‡•á, ‡§§‡§¨ ‡§§‡§ï ‡§°‡•ç‡§∞‡§æ‡§á‡§µ‡§ø‡§Ç‡§ó ‡§Ø‡§æ ‡§Æ‡§∂‡•Ä‡§®‡§∞‡•Ä ‡§ö‡§≤‡§æ‡§®‡•á ‡§∏‡•á ‡§¨‡§ö‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§\n",
      "\n",
      "‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§á‡§® ‡§∏‡§æ‡§á‡§° ‡§á‡§´‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡§æ ‡§≠‡•Ä ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§π‡•ã, ‡§§‡•ã ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§Ö‡§™‡§®‡•á ‡§π‡•á‡§≤‡•ç‡§•‡§ï‡•á‡§Ø‡§∞ ‡§™‡•ç‡§∞‡§¶‡§æ‡§§‡§æ ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§\n"
     ]
    }
   ],
   "source": [
    "output=chat_model.invoke(prompt.format(medicine='paracetamol',language='Hindi'))\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922cd8dd-0dea-4b39-a0d3-67a66c8616f2",
   "metadata": {},
   "source": [
    "## Example -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c7c3490-2639-4391-9680-9869da2b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_2=\"\"\"\" You are a expert data scientist , give responses to the following question: {question}. \n",
    " Do not use technical words, give easy to understand responses. Your response should be in {language}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f2ee6fe-2eb0-4582-a31a-a8998e81078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2=PromptTemplate(input_variables=[\"question\",\"language\"],template=template_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cac8175-1e6e-43ea-b9fd-a05931a70b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2=chat_model.invoke(prompt_2.format(question=\"what is Large language model\",language=\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2faabfb2-2258-489e-958b-a765b9eafce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A large language model is a kind of computer program that has been trained to understand and generate human-like text. Think of it like a very advanced version of autocorrect or predictive text on your phone. It's been trained on a wide range of internet text, but it doesn't know anything specific about who wrote those texts.\\n\\nSo, it's like a big parrot that's learned to mimic human language very well. It can write text that seems quite human-like, but it's important to remember it doesn't truly understand what it's saying - it's just predicting what comes next based on what it's seen before. It's a tool that can be used to help generate ideas, write essays, answer questions, and a lot more.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7004b-6a7d-4adf-9017-5bf6d6badcc1",
   "metadata": {},
   "source": [
    "## # text to emoji conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "319b0bab-9da5-4a97-9efd-89cae9b49020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to emoji conversion\n",
    "temp_3= \"\"\" Convert the following list of sports to emojis:\n",
    "1. Cricket,\n",
    "2. Football,\n",
    "3. Tennis,\n",
    "4. Cycling,\n",
    "5. Volleyball,\n",
    "6.chess\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8964a878-6304-4598-af05-8f9246b61c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model.invoke(temp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59c1c96c-3625-4ceb-9ce6-489139c8f253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. üèè\n",
      "2. üèà\n",
      "3. üéæ\n",
      "4. üö¥\n",
      "5. üèê\n",
      "6. ‚ôüÔ∏è\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8354f2-1b49-4673-ab5f-17c0695fdc67",
   "metadata": {},
   "source": [
    "## Entity Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a51bd5ed-8f46-4e14-9150-249d9ae72117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "text = \"Elon Musk was born in Pretoria and is the CEO of SpaceX. Chandan working in IBM at Noida\"\n",
    "temp_3 = f\"From the text: '{text}', extract the named entities and categorize them as follows: {{name:, city:, org:}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58b8ad7c-a9a8-4fe2-b0d0-0b8daf38bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3=chat_model.invoke(temp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bab8d9f7-359f-4773-920e-a079f3962b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{name: Elon Musk, Chandan, city: Pretoria, Noida, org: SpaceX, IBM}\n"
     ]
    }
   ],
   "source": [
    "print(result_3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116e484-7836-4990-aebe-9976e49e56a8",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6beb467-238d-4b10-b2f6-b03b43758b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2d960fa-a33e-413d-a2cc-d0325b9cc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model_1=ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),model='gpt-4',temperature=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6574a82-deb1-4f1e-a03b-ddcebad56df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"ChatGPT is an artificial intelligence language model developed by OpenAI. It is designed to engage in human-like text conversations. It generates responses to text inputs by predicting the next word in a sentence, based on the context of the conversation. It has been trained on a diverse range of internet text, but it doesn't know specific documents or sources that were part of its training set. It's important to note that while ChatGPT can generate very human-like responses, it doesn't have beliefs or desires, and all its outputs are simulations.\")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model_1.invoke(\n",
    "    [\n",
    "        HumanMessage(content='what is chatgpt')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec279760-340a-4463-a55b-19b2337b0804",
   "metadata": {},
   "source": [
    "## Exmple 2: ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54a5bbc8-68a8-42b0-8555-0d226029bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "ChatPromptTemplate,\n",
    "SystemMessagePromptTemplate,\n",
    "HumanMessagePromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "877878c9-ad69-49e8-955c-e1ee2961fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"You will provided with the sample text. \\\n",
    "Your task is to translate the text into {output_language} language \\\n",
    "and summarize the translated text in at most {max_words} words. \\ \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "970e7e1d-a300-4b78-871c-e6267b4d2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "605a44ee-bb8c-4564-8816-84292596bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{sample_text}\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb4ca651-8847-4ca6-aeb3-4cfeb779e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§Æ‡•à‡§Ç ‡§∏‡§™‡•ç‡§§‡§æ‡§π‡§æ‡§Ç‡§§ ‡§ï‡§æ ‡§¨‡•á‡§∏‡§¨‡•ç‡§∞‡•Ä ‡§∏‡•á ‡§á‡§Ç‡§§‡§ú‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§ \n",
      "\n",
      "‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™: ‡§Æ‡•à‡§Ç ‡§∏‡§™‡•ç‡§§‡§æ‡§π‡§æ‡§Ç‡§§ ‡§ï‡•Ä ‡§â‡§§‡•ç‡§∏‡•Å‡§ï‡§§‡§æ ‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt_template, human_message_prompt_template])\n",
    "final_prompt = chat_prompt_template.format_prompt(output_language=\"Hindi\", max_words=15,\n",
    "                          sample_text=\"Estoy deseando que llegue el fin de semana.\").to_messages()\n",
    "# generate the output by calling ChatGPT model and passing the prompt\n",
    "completion = chat_model_1.invoke(final_prompt)\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae100c6-bac5-4fd6-8598-1f8f5931a87a",
   "metadata": {},
   "source": [
    "## Exmple 3: ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ff08219-e009-4419-adfd-865dfe9a3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fac86a3e-0d3a-4e9d-870f-9148faa01c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model_2=ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),model='gpt-3.5-turbo-1106',temperature=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14ad6df7-8ac3-416b-98e3-9dea8b8a4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7df62e8-391b-4457-9cc8-55eb35636664",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model_2.invoke([HumanMessage(content=\"Tell me about large language Model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3269ab21-213f-419a-8c5c-5a56f15b6979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A large language model is a type of artificial intelligence system that is trained to understand and generate human language. These models are typically based on deep learning techniques and are capable of processing and generating large amounts of text data.\\n\\nLarge language models are trained on massive datasets of text, such as books, articles, and websites, in order to learn the patterns and structures of human language. This allows them to understand and generate natural-sounding language, and they can be used for a variety of tasks such as language translation, text generation, and natural language processing.\\n\\nOne of the most well-known large language models is OpenAI's GPT-3 (Generative Pre-trained Transformer 3), which has 175 billion parameters and is capable of performing a wide range of language tasks. These models have the potential to revolutionize the way we interact with technology and have applications in fields such as customer service, content generation, and language understanding. However, they also raise ethical and privacy concerns, as they have the potential to generate highly convincing fake text and may be used for malicious purposes.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3da9cc06-0b91-4338-94c3-e87a91399f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model_2.invoke([SystemMessage(content=\"Consider you are data scientist\"),\n",
    "    HumanMessage(content=\"Tell me about large language Model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "945d46e4-05cd-46a5-b152-21ee5d4d766e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A large language model is a type of artificial intelligence (AI) model that is designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of understanding and generating natural language with a high degree of accuracy.\\n\\nLarge language models are typically based on deep learning techniques, such as recurrent neural networks (RNNs) or transformer architectures. They can be used for a wide range of natural language processing (NLP) tasks, including language translation, text summarization, question-answering, and language generation.\\n\\nOne of the most well-known large language models is OpenAI's GPT-3 (Generative Pre-trained Transformer 3), which has 175 billion parameters and has demonstrated impressive capabilities in understanding and generating human-like text.\\n\\nLarge language models have the potential to revolutionize many aspects of communication, content generation, and information retrieval. However, they also raise ethical and societal concerns, particularly regarding the potential for misuse and the generation of biased or harmful content.\\n\\nOverall, large language models represent a significant advancement in the field of AI and NLP and have the potential to have a profound impact on various industries and applications.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562853e3-c821-44da-ab74-3f21a2ccbf0b",
   "metadata": {},
   "source": [
    "### Example 4:Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c451947e-ca2e-40f6-b0e3-20138c85e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model_2.generate(\n",
    "    [[SystemMessage(content=\"Consider you are expert Data Scientst and having Knowledge of Deep Learning and NLP\"),\n",
    "    HumanMessage(content=\"Explain what is Large Language Model\")],\n",
    "    [SystemMessage(content=\"Consider You are doctor having knowledge of heathcare domain\"),\n",
    "    HumanMessage(content=\"Explain what is Large Language Model\")]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59d35fd5-50a8-4042-bbdf-1ebe2938a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 432,\n",
       "  'prompt_tokens': 63,\n",
       "  'total_tokens': 495},\n",
       " 'model_name': 'gpt-3.5-turbo-1106',\n",
       " 'system_fingerprint': 'fp_89448ee5dc'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8271466-3c60-43ad-91f4-8c59250424e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A large language model is a type of deep learning model that is specifically designed to understand and generate human language. These models are trained on vast amounts of text data to learn the underlying patterns and structures of language. They are capable of understanding and generating human-like text, and can be used for a wide range of natural language processing (NLP) tasks such as language translation, text summarization, question answering, and more.\\n\\nLarge language models are typically built using neural network architectures, such as transformer models, and are trained on massive datasets to effectively capture the complex and nuanced nature of human language. These models have the ability to generate coherent and contextually relevant text, and have been instrumental in advancing the state-of-the-art in NLP.\\n\\nExamples of large language models include OpenAI's GPT-3 (Generative Pre-trained Transformer 3) and Google's BERT (Bidirectional Encoder Representations from Transformers), which have demonstrated remarkable capabilities in understanding and generating natural language text. These models have significantly impacted various NLP applications and continue to be a focus of research and development in the field of deep learning and NLP.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0bdcd83-2fbc-4b41-addd-5e540c87434d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A Large Language Model is a type of artificial intelligence (AI) model that is designed to understand and generate human language. These models are trained on vast amounts of text data from the internet and other sources, allowing them to learn the patterns and nuances of language.\\n\\nLarge Language Models use a technique called deep learning, which involves training a neural network with multiple layers to process and understand language. This allows the model to generate human-like text, answer questions, translate languages, and perform other language-related tasks.\\n\\nOne of the most well-known examples of a Large Language Model is OpenAI's GPT-3 (Generative Pre-trained Transformer 3), which has 175 billion parameters and is capable of performing a wide range of natural language processing tasks.\\n\\nThese models have the potential to revolutionize many aspects of healthcare, including medical documentation, patient communication, and clinical decision support. They can help automate repetitive tasks, improve the accuracy of natural language processing in electronic health records, and assist healthcare professionals in accessing and interpreting medical literature and research.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545656b3-ad68-4236-b420-d304b81800b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
